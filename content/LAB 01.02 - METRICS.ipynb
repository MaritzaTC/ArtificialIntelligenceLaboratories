{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mIUht7RmuON"
      },
      "source": [
        "# LAB 01.02 - Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mzSMwxXmuOO"
      },
      "outputs": [],
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/ai4eng.v1/main/content/init.py\n",
        "import init, inspect; init.init(force_download=False); init.get_weblink()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpmadr6FmuOP"
      },
      "outputs": [],
      "source": [
        "from local.lib.rlxmoocapi import submit, session\n",
        "session.LoginSequence(endpoint=init.endpoint, course_id=init.course_id, lab_id=\"L01.02\", varname=\"student\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyJvwr8PmuOP"
      },
      "source": [
        "## General remark\n",
        "\n",
        "You do not need to use Python to solve the problems in this notebook, you can use any tool of your choice (Excel, etc.), including **pen and paper**. But\n",
        "\n",
        "### If you want to try out in Python\n",
        "\n",
        "- `numpy` is the Python library used for vectors\n",
        "- there are operations that take a vector and produce another vector (i.e. `np.log`)\n",
        "- there are operations that take a vector and procude a number (i.e. `np.mean`)\n",
        "- there are operations that take two vectors and produce a number (see the **HINTs** below)\n",
        "- etc.\n",
        "\n",
        "For instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Yota9DeomuOP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.array([1,2,3,4])\n",
        "\n",
        "# the log of each element of the vector\n",
        "print ( \"the log   =\", np.log(v1)  )\n",
        "\n",
        "# the mean of all elements of the vector\n",
        "print ( \"the mean  =\",  np.mean(v1)  )\n",
        "\n",
        "# multiply all elements of a vector with a scalar\n",
        "print (\"times two =\", 2*v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17qJBnNDmuOP"
      },
      "source": [
        "you can always check the type of any variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4kPj5ZLmuOP"
      },
      "outputs": [],
      "source": [
        "a = 2.0\n",
        "type(v1), type(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IGOriAmuOP"
      },
      "source": [
        "## Task 01. Accuracy\n",
        "\n",
        "Compute the percentage of correct predictions **accuracy** (see [here](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Definitions)) for the following model output (`predicted`) and ground truth (`actual`).\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**CHALLENGE**: use Python with [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
        "\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5aubEA8muOP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "t1_actual    = np.random.randint(2, size=20)\n",
        "t1_predicted = np.abs(t1_actual*(np.random.random(size=20)>(np.random.random()*.9+.05)).astype(int))\n",
        "print (\"actual   \", \", \".join([str(i) for i in t1_actual]))\n",
        "print (\"predicted\", \", \".join([str(i) for i in t1_predicted]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x26BFEJymuOQ"
      },
      "source": [
        "Assign the value of your computation to the `accuracy` variable, **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHNvE6Z8muOQ",
        "outputId": "afb63055-4f35-4572-9234-992d254e2eb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.65"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(t1_actual, t1_predicted)\n",
        "round(accuracy, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rr-vgLkmuOQ"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yDtATfBmuOQ"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_01\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8PHuHS3muOQ"
      },
      "source": [
        "## Task 2: Sensitivity\n",
        "\n",
        "Compute the sensitivity metric [aka the _True Positive Rate_ or _Recall_ see [Sensitivity on Wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)] for the following model output (`predicted`) and ground truth (`actual`)\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**Challenge**: Use Python [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
        "\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEBP11FcmuOQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "t2_predicted = np.random.randint(2, size=20)\n",
        "t2_actual = np.random.randint(2, size=20)\n",
        "t2_predicted[np.argwhere(t2_actual==1)[0][0]]=0\n",
        "print (\"actual   \", \", \".join([str(i) for i in t2_actual]))\n",
        "print (\"predicted\", \", \".join([str(i) for i in t2_predicted]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciGE373CmuOQ"
      },
      "source": [
        "Assign the value of your computation to the `tpr` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o41vMHvwmuOQ",
        "outputId": "0d6b452a-5a48-4f53-9c21-97f2a033aaae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.364"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "tpr = recall_score(t2_actual,t2_predicted)\n",
        "round(tpr,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nsERxbOmuOQ"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bsys2quAmuOQ"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_02\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLLoh3BzmuOQ"
      },
      "source": [
        "## Task 3: Evaluation in New York City Taxi Trip Duration Kaggle Competition\n",
        "\n",
        "Understand the data and the evaluation metric (**Root Mean Squared Logarithmic Error**, RMSLE) of the following Kaggle competition\n",
        "\n",
        "- [https://www.kaggle.com/c/nyc-taxi-trip-duration/](https://www.kaggle.com/c/nyc-taxi-trip-duration/)\n",
        "\n",
        "Observe that this competition is a **regression task** as we are measuring the difference in prediction with respect to the actual.\n",
        "\n",
        "For instance, the following model predictions and ground truth:\n",
        "\n",
        "    actual    [66 37 22]\n",
        "    predicted [79 51 67]\n",
        "    \n",
        "produce a **RMSLE** of 0.66 aprox.\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n",
        "\n",
        "**Challenge**: For python use numpy function `np.log` or `np.log1p`\n",
        "\n",
        "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeHzw1qcmuOQ"
      },
      "outputs": [],
      "source": [
        "t3_actual    = np.random.randint(80,size=15)+20\n",
        "t3_predicted = np.random.randint(80,size=15)+20\n",
        "print (\"actual   \", t3_actual)\n",
        "print (\"predicted\", t3_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87HIHcVXmuOQ"
      },
      "source": [
        "Assign the value of your computation to the `rmsle` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0lKzHx5muOQ",
        "outputId": "48c6a1d9-bd5b-4c1d-ffc2-14bdf76e1382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.652"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "rmsle = np.sqrt(np.mean(np.square(np.log(t3_predicted + 1) - np.log(t3_actual + 1))))\n",
        "round(rmsle,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Pf9KZcmuOQ"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "8RnmkBGNmuOQ"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_03\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThTqTeLfmuOQ"
      },
      "source": [
        "## Task 4: Evaluation in Shelter Animal Outcomes Kaggle Competition\n",
        "\n",
        "Understand the data and the evaluation metric (**Multiclass Logaritmic Loss**, _logloss_) of the following Kaggle competition\n",
        "\n",
        "- [https://www.kaggle.com/c/shelter-animal-outcomes/](https://www.kaggle.com/c/shelter-animal-outcomes/)\n",
        "\n",
        "Observe that this competition is a **classification task with 5 classes** and, for each item, the model produces a probability for each class. Classes are numbered from 0 to 4.\n",
        "\n",
        "For instance, the following represents the model output for **three items**\n",
        "\n",
        "    [[0.17 0.27 0.03 0.31 0.21]\n",
        "     [0.09 0.44 0.02 0.15 0.3 ]\n",
        "     [0.26 0.18 0.25 0.2  0.11]]\n",
        "     \n",
        "Where the classes with gretest probability assigned by the model are\n",
        "\n",
        "- class 3 for the first item (with 0.31 probability)\n",
        "- class 1 for the second item (with 0.44 probability)\n",
        "- class 0 for the third item (with 0.26 probability)\n",
        "\n",
        "The class labels are expressed as a similar matrix, but with 0/1\n",
        "For instance, the ground truth for the corresponding three items above, could be:\n",
        "\n",
        "    [[0 0 0 1 0]\n",
        "     [0 0 1 0 0]\n",
        "     [1 0 0 0 0]]\n",
        "\n",
        "and will produce a **logloss** of approx 2.14\n",
        "\n",
        "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2amEOlVmuOQ",
        "outputId": "d35bc6bb-93ee-4fa3-e796-3b8cbaa04e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual\n",
            "[[0 1 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]]\n",
            "\n",
            "predicted\n",
            "[[0.25 0.16 0.24 0.25 0.1 ]\n",
            " [0.13 0.26 0.18 0.21 0.23]\n",
            " [0.23 0.25 0.12 0.14 0.27]\n",
            " [0.21 0.29 0.13 0.18 0.19]\n",
            " [0.16 0.18 0.15 0.25 0.25]\n",
            " [0.24 0.27 0.19 0.19 0.11]\n",
            " [0.22 0.21 0.12 0.25 0.2 ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "t4_predicted = np.random.random(size=(7,5)).T+0.5\n",
        "t4_predicted = np.round((t4_predicted/np.sum(t4_predicted,axis=0)),2).T\n",
        "\n",
        "t4_actual = np.eye(5)[np.random.randint(5,size=len(t4_predicted))].astype(int)\n",
        "\n",
        "print (\"actual\")\n",
        "print (t4_actual)\n",
        "print (\"\\npredicted\")\n",
        "print (t4_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQiS_Q0amuOQ"
      },
      "source": [
        "Assign the value of your computation to the `logloss` variable **with three decimal places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu2Bpd4vmuOQ",
        "outputId": "79beff3d-ab39-46d3-c552-591cabcaa8c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.55"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "logloss = -np.mean(np.sum(t4_actual * np.log(t4_predicted), axis=1))\n",
        "round(logloss, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lax2FyUzmuOQ"
      },
      "source": [
        "#### submit your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "XOH_s3samuOR"
      },
      "outputs": [],
      "source": [
        "student.submit_task(globals(), task_id=\"task_04\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}